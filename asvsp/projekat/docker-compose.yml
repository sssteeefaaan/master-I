version: "3.7"
services:

  namenode:
    image: bde2020/hadoop-namenode:${HADOOP_MASTERNODE_VERSION:-2.0.0-hadoop3.2.1-java8}
    container_name: namenode
    volumes:
      - namenode-data:/hadoop/dfs/name
      - ./batch-dataset:/home/projekat/batch-dataset
    environment:
      - CLUSTER_NAME=projekat
    env_file:
      - ./docker-spark/hadoop.env
    mem_limit: 700M
    ports:
      - ${NAMENODE_PORT_01:-9870}:9870
      - ${NAMENODE_PORT_02:-9000}:9000
    restart: unless-stopped

  datanode-01:
    image: bde2020/hadoop-datanode:${HADOOP_DATANODE_VERSION:-2.0.0-hadoop3.2.1-java8}
    container_name: datanode-01
    depends_on:
      - namenode
    volumes:
      - datanode-01-data:/hadoop/dfs/data
    env_file:
      - ./docker-spark/hadoop.env
    mem_limit: 700M
    restart: unless-stopped

  datanode-02:
    image: bde2020/hadoop-datanode:${HADOOP_DATANODE_VERSION:-2.0.0-hadoop3.2.1-java8}
    container_name: datanode-02
    depends_on:
      - namenode
    volumes:
      - datanode-02-data:/hadoop/dfs/data
    env_file:
      - ./docker-spark/hadoop.env
    mem_limit: 700M
    restart: unless-stopped

  hue:
    image: gethue/hue:${HUE_VERSION:-20201111-135001}
    container_name: hue
    hostname: hue
    dns: 8.8.8.8
    ports:
      - ${HUE_PORT:-8888}:8888
    volumes:
      - ./docker-spark/conf.dist:/usr/share/hue/desktop/conf
    depends_on:
      - namenode
    mem_limit: 200M
    restart: unless-stopped

  spark-master:
    image: bde2020/spark-master:${SPARK_MASTER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-master
    ports:
      - ${SPARK_MASTER_PORT_01:-8080}:8080
      - ${SPARK_MASTER_PORT_02:-7077}:7077
    environment:
      - PYSPARK_PYTHON=python3
    env_file:
      - ./docker-spark/hadoop.env
    volumes:
      - ./batch-processing:/home/projekat/batch-processing
      - ./realtime-processing:/home/projekat/realtime-processing
    mem_limit: 1024M
    restart: unless-stopped

  spark-worker-01:
    image: bde2020/spark-worker:${SPARK_WORKER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-worker-01
    depends_on:
      - spark-master
    ports:
      - ${SPARK_WORKER_01_PORT:-8081}:8081
    env_file:
      - ./docker-spark/hadoop.env
    mem_limit: 1024M
    restart: unless-stopped
  spark-worker-02:
    image: bde2020/spark-worker:${SPARK_WORKER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-worker-02
    depends_on:
      - spark-master
    ports:
      - ${SPARK_WORKER_02_PORT:-8082}:8081
    env_file:
      - ./docker-spark/hadoop.env
    mem_limit: 1024M
    restart: unless-stopped

  zookeeper:
    image: bitnami/zookeeper:${ZOOKEEPER_VERSION:-}
    container_name: zookeeper
    ports:
      - ${ZOOKEEPER_PORT:-2181}:2181
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    mem_limit: 700M
    restart: unless-stopped

  kafka:
    image: bitnami/kafka:${KAFKA_VERSION:-}
    container_name: kafka
    ports:
      - ${KAFKA_PORT_EXTERNAL:-19092}:19092
      - ${KAFKA_PORT_INTERNAL:-9092}:9092
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:19092
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:19092
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1
    depends_on:
      - zookeeper
    mem_limit: 700M
    restart: unless-stopped
  producer-grain-prices:
    build:
      args:
        PYTHON_PRODUCER_VERSION: ${PYTHON_PRODUCER_VERSION:-}
      context: ./kafka-producer
    container_name: producer-grain-prices
    volumes:
      - ./kafka-producer:/app:ro
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: grain-prices
      DATASET_API_LINK: ${DATASET_GRAIN_PRICES_API_LINK:-https://agtransport.usda.gov/resource/g92w-8cn7.json}
    depends_on:
      - kafka
    mem_limit: 200M
    restart: unless-stopped

  # grafana:
  #   image: grafana/grafana:${GRAFANA_VERSION:-7.5.7}
  #   ports:
  #     - ${GRAFANA_PORT:-3000}:3000
  #   restart: unless-stopped
  #   volumes:
  #     - grafana-data:/var/lib/grafana

  # producer-grain-basis:
  #   build:
        # args:
        #   PYTHON_PRODUCER_VERSION: ${PYTHON_PRODUCER_VERSION:-}
        # context: ./kafka-producer
  #   container_name: producer-grain-basis
  #   volumes:
  #     - ./kafka-producer:/app:ro
  #   environment:
  #     KAFKA_BROKER: kafka:9092
  #     KAFKA_TOPIC: grain-basis
  #     DATASET_API_LINK: ${DATASET_GRAIN_BASIS_API_LINK:-https://agtransport.usda.gov/resource/v85y-3hep.json}
  #   depends_on:
  #     - kafka
  #   mem_limit: 200M
  #   restart: unless-stopped

  es-setup:
    build:
      context: ./elk-stack/setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - ./elk-stack/setup/entrypoint.sh:/entrypoint.sh:ro,Z
      - ./elk-stack/setup/helpers.sh:/helpers.sh:ro,Z
      - ./elk-stack/setup/roles:/roles:ro,Z
      - es-setup:/state:Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      METRICBEAT_INTERNAL_PASSWORD: ${METRICBEAT_INTERNAL_PASSWORD:-}
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      HEARTBEAT_INTERNAL_PASSWORD: ${HEARTBEAT_INTERNAL_PASSWORD:-}
      MONITORING_INTERNAL_PASSWORD: ${MONITORING_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch
    mem_limit: 200M
  elasticsearch:
    build:
      context: ./elk-stack/elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elk-stack/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - ${ELASTICSEARCH_PORT_01:-9200}:9200
      - ${ELASTICSEARCH_PORT_02:-9300}:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      discovery.type: single-node
    restart: unless-stopped
    mem_limit: 1024M

  kibana:
    build:
      context: ./elk-stack/kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elk-stack/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - ${KIBANA_PORT:-5601}:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped
    mem_limit: 600M

volumes:
  namenode-data:
  datanode-01-data:
  datanode-02-data:
  es-setup:
  elasticsearch-data: