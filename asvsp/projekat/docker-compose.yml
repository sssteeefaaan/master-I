version: "3.7"
services:

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    volumes:
      - namenode-data:/hadoop/dfs/name
      - ./batch-dataset:/home/projekat/batch-dataset
    environment:
      - CLUSTER_NAME=projekat
    env_file:
      - ./docker-spark/hadoop.env
    ports:
      - ${NAMENODE_PORT_01:-9870}:9870
      - ${NAMENODE_PORT_02:-9000}:9000

  datanode-01:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-01
    depends_on:
      - namenode
    volumes:
      - datanode-01-data:/hadoop/dfs/data
    env_file:
      - ./docker-spark/hadoop.env

  datanode-02:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-02
    depends_on:
      - namenode
    volumes:
      - datanode-02-data:/hadoop/dfs/data
    env_file:
      - ./docker-spark/hadoop.env

  hue:
    image: gethue/hue:20201111-135001
    container_name: hue
    hostname: hue
    dns: 8.8.8.8
    ports:
      - ${HUE_PORT:-8888}:8888
    volumes:
      - ./docker-spark/conf.dist:/usr/share/hue/desktop/conf
    depends_on:
      - namenode

  spark-master:
    image: bde2020/spark-master:3.0.1-hadoop3.2
    container_name: spark-master
    ports:
      - ${SPARK_MASTER_PORT_01:-8080}:8080
      - ${SPARK_MASTER_PORT_02:-7077}:7077
    environment:
      - PYSPARK_PYTHON=python3
    env_file:
      - ./docker-spark/hadoop.env
    volumes:
      - ./batch-processing:/home/projekat/batch-processing

  spark-worker-01:
    image: bde2020/spark-worker:3.0.1-hadoop3.2
    container_name: spark-worker-01
    depends_on:
      - spark-master
    ports:
      - ${SPARK_WORKER_01_PORT:-8081}:8081
    env_file:
      - ./docker-spark/hadoop.env

  spark-worker-02:
    image: bde2020/spark-worker:3.0.1-hadoop3.2
    container_name: spark-worker-02
    depends_on:
      - spark-master
    ports:
      - ${SPARK_WORKER_02_PORT:-8082}:8081
    env_file:
      - ./docker-spark/hadoop.env

  zookeeper:
    image: 'bitnami/zookeeper:latest'
    container_name: zookeeper
    ports:
      - ${ZOOKEEPER_PORT:-2181}:2181
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: 'bitnami/kafka:latest'
    container_name: kafka
    ports:
      - ${KAFKA_PORT_EXTERNAL:-19092}:19092
      - ${KAFKA_PORT_INTERNAL:-9092}:9092
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:19092
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:19092
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1
    depends_on:
      - zookeeper
  producer-grain-prices:
    build: ./kafka-producer
    container_name: producer-grain-prices
    volumes:
      - ./kafka-producer:/app:ro
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: grain-prices
      DATASET_API_LINK: ${DATASET_GRAIN_PRICES_API_LINK:-https://agtransport.usda.gov/resource/g92w-8cn7.json}
    depends_on:
      - kafka
  producer-grain-basis:
    build: ./kafka-producer
    container_name: producer-grain-basis
    volumes:
      - ./kafka-producer:/app:ro
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: grain-basis
      DATASET_API_LINK: ${DATASET_GRAIN_BASIS_API_LINK:-https://agtransport.usda.gov/resource/v85y-3hep.json}
    depends_on:
      - kafka
  es-setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - es-certs:/usr/share/elasticsearch/config/certs
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: es-node-01\n"\
          "    dns:\n"\
          "      - es-node-01\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es-node-02\n"\
          "    dns:\n"\
          "      - es-node-02\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "Waiting for Elasticsearch availability";
        until curl -s --cacert config/certs/ca/ca.crt https://es-node-01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es-node-01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/es-node-01/es-node-01.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120

  es-node-01:
    depends_on:
      es-setup:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - es-certs:/usr/share/elasticsearch/config/certs
      - es-node-01-data:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=es-node-01
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es-node-01,es-node-02
      - discovery.seed_hosts=es-node-02
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es-node-01/es-node-01.key
      - xpack.security.http.ssl.certificate=certs/es-node-01/es-node-01.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.http.ssl.verification_mode=certificate
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es-node-01/es-node-01.key
      - xpack.security.transport.ssl.certificate=certs/es-node-01/es-node-01.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200",
        ]
      interval: 60s
      timeout: 20s
      retries: 50

  es-node-02:
    depends_on:
      - es-node-01
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - es-certs:/usr/share/elasticsearch/config/certs
      - es-node-02-data:/usr/share/elasticsearch/data
    environment:
      - node.name=es-node-02
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es-node-01,es-node-02
      - discovery.seed_hosts=es-node-01
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es-node-02/es-node-02.key
      - xpack.security.http.ssl.certificate=certs/es-node-02/es-node-02.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.http.ssl.verification_mode=certificate
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es-node-02/es-node-02.key
      - xpack.security.transport.ssl.certificate=certs/es-node-02/es-node-02.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200",
        ]
      interval: 60s
      timeout: 20s
      retries: 50

  kibana:
    depends_on:
      es-node-01:
        condition: service_healthy
      es-node-02:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    volumes:
      - es-certs:/usr/share/kibana/config/certs
      - kibana-data:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=https://es-node-01:9200
      - ELASTICSEARCH_USERNAME=${KIBANA_USERNAME}
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
    mem_limit: ${MEM_LIMIT}

volumes:
  namenode-data:
  datanode-01-data:
  datanode-02-data:
  es-certs:
  es-node-01-data:
  es-node-02-data:
  kibana-data: